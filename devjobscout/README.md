# ğŸ’¼ DevJobScout

**Tu asistente inteligente para bÃºsqueda de empleo automatizada**

DevJobScout es una herramienta avanzada de IA que automatiza completamente tu bÃºsqueda de empleo. Extrae tu perfil profesional desde mÃºltiples fuentes (CV, GitHub, LinkedIn), analiza automÃ¡ticamente tus skills, sugiere roles ideales y busca las mejores ofertas en LinkedIn, InfoJobs y RemoteOK.

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¯ ExtracciÃ³n Inteligente de Perfil
- **ğŸ“„ Parser de CV avanzado**: Extrae tecnologÃ­as, experiencia, roles y empresas desde PDF, TXT o DOCX
- **ğŸ™ ExtracciÃ³n profunda de GitHub**: Navega tu perfil con IA para obtener:
  - Lenguajes principales con porcentajes
  - Repositorios destacados con estrellas
  - Contribuciones del Ãºltimo aÃ±o
  - Frameworks y herramientas inferidas
  - Nivel de actividad y especializaciones
- **ğŸ’¼ ExtracciÃ³n de LinkedIn**: Stack tecnolÃ³gico y experiencia profesional
- **ğŸ”— Perfil unificado**: Combina toda la informaciÃ³n en un Ãºnico perfil enriquecido

### ğŸ¤– AnÃ¡lisis AutomÃ¡tico con IA
- **ğŸ“ DetecciÃ³n automÃ¡tica de nivel**: Junior, Mid-Level o Senior
- **ğŸ’¡ Sugerencia de roles ideales**: Basado en tu stack completo
- **ğŸ“Š Scoring de fortaleza del perfil**: EvalÃºa la completitud de tu perfil (0-100)
- **ğŸ” GeneraciÃ³n de queries optimizadas**: BÃºsquedas automÃ¡ticas personalizadas
- **ğŸ¯ Soft skills detection**: Extrae habilidades blandas de tu bio

### ğŸŒ Scraping Multi-Plataforma
- **ğŸ”µ LinkedIn**: BÃºsqueda con filtros avanzados y autenticaciÃ³n persistente
- **ğŸŸ  InfoJobs**: Scraping de ofertas con filtros personalizables
- **ğŸŸ¢ RemoteOK**: Enfocado en trabajos 100% remotos
- **ğŸ¤– Browser-use**: NavegaciÃ³n autÃ³noma con visiÃ³n por computadora

### ğŸ¯ Filtrado Inteligente
- **âœ… Match con tech stack**: PuntuaciÃ³n basada en coincidencias
- **âŒ DetecciÃ³n de red flags**: Filtra "rockstar", "ninja", "fast-paced", etc.
- **ğŸ’° Filtro de salario**: Establece tu mÃ­nimo aceptable
- **ğŸ“ Preferencias de ubicaciÃ³n**: Remote, hÃ­brido o presencial
- **ğŸ† Sistema de scoring 0-100**: Solo ves las mejores oportunidades

### ğŸ”” Notificaciones AutomÃ¡ticas
- **ğŸ“± Telegram**: Alertas instantÃ¡neas de nuevas ofertas
- **ğŸ“ Notion**: Guarda ofertas automÃ¡ticamente en tu workspace
- **ğŸ“Š Dashboard**: VisualizaciÃ³n completa en interfaz web

### ğŸ–¥ï¸ Interfaz Completa
- **ğŸ¨ UI moderna con Streamlit**: FÃ¡cil de usar
- **ğŸ” GestiÃ³n de autenticaciÃ³n**: Login manual persistente
- **ğŸ“ˆ VisualizaciÃ³n de resultados**: Ordenados por relevancia
- **ğŸ’¾ ExportaciÃ³n de datos**: JSON, CSV y mÃ¡s

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Requisitos Previos

- **Python 3.11+**
- **[uv](https://github.com/astral-sh/uv)** (gestor de paquetes rÃ¡pido)
- **Git**

### InstalaciÃ³n

```bash
# Clonar el repositorio
git clone <tu-repositorio>
cd devjobscout

# Instalar dependencias
uv sync

# Configurar variables de entorno
cp .env.example .env
# Edita .env con tu API key de browser-use
```

## âš™ï¸ ConfiguraciÃ³n

### 1. Variables de Entorno

Edita el archivo `.env` con tus credenciales:

```bash
# Browser-use API Key (OBLIGATORIO)
# ObtÃ©n tu key en: https://browser-use.com
BROWSER_USE_API_KEY=tu_api_key_aqui

# Telegram (OPCIONAL - para notificaciones)
TELEGRAM_BOT_TOKEN=tu_bot_token
TELEGRAM_CHAT_ID=tu_chat_id

# Notion (OPCIONAL - para guardar ofertas)
NOTION_TOKEN=tu_notion_token
NOTION_DATABASE_ID=tu_database_id
```

### 2. AutenticaciÃ³n de Plataformas

LinkedIn requiere autenticaciÃ³n para acceder a ofertas. DevJobScout incluye un sistema de login manual con persistencia de sesiÃ³n.

#### OpciÃ³n A - Desde la interfaz web:
```bash
./run.sh  # o: uv run streamlit run app.py
```
1. Ve al tab **"ğŸ” AutenticaciÃ³n"**
2. Haz clic en "Login Manual LinkedIn"
3. Se abre un navegador real donde haces login normalmente
4. La sesiÃ³n se guarda en `sessions/linkedin_session.json`

#### OpciÃ³n B - Desde lÃ­nea de comandos:
```bash
uv run python src/auth/linkedin_auth.py
```

**ğŸ“– GuÃ­a completa de autenticaciÃ³n**: [AUTH_GUIDE.md](AUTH_GUIDE.md)

### 3. Configurar Notificaciones (Opcional)

#### Telegram
1. Habla con [@BotFather](https://t.me/botfather) â†’ `/newbot`
2. Guarda el token
3. ObtÃ©n tu Chat ID con [@userinfobot](https://t.me/userinfobot)
4. AgrÃ©galos al `.env`

#### Notion
1. Crea integraciÃ³n en [notion.so/my-integrations](https://www.notion.so/my-integrations)
2. Copia el token
3. Crea base de datos y compÃ¡rtela con la integraciÃ³n
4. Copia el Database ID (de la URL)
5. AgrÃ©galos al `.env`

## ğŸ® GuÃ­a de Uso

### Interfaz Web (Recomendado)

```bash
cd devjobscout
./run.sh
# Se abre automÃ¡ticamente en http://localhost:8501
```

#### Flujo de Trabajo Completo

**Paso 1: Construir tu Perfil** (Tab "ğŸ“Š Perfil")

1. **Sube tu CV**:
   - Formatos soportados: PDF, TXT, DOCX
   - Extrae: tecnologÃ­as, experiencia, roles, empresas, contacto

2. **Extrae de GitHub**:
   - Ingresa tu URL de GitHub (ej: `https://github.com/username`)
   - Extrae automÃ¡ticamente:
     - Lenguajes principales con %
     - Top repos con estrellas
     - Contribuciones Ãºltimo aÃ±o
     - Frameworks/herramientas inferidas
     - Nivel de actividad

3. **Extrae de LinkedIn** (opcional):
   - Requiere autenticaciÃ³n previa
   - Complementa info profesional

4. **Revisa el Perfil Unificado**:
   - Ve toda tu info consolidada
   - Edita manualmente si es necesario
   - El sistema genera un contexto enriquecido automÃ¡ticamente

**Paso 2: AnÃ¡lisis AutomÃ¡tico** (Tab "ğŸ¯ AnÃ¡lisis")

El sistema analiza tu perfil y te muestra:

- **Nivel detectado**: Junior / Mid-Level / Senior
- **Roles sugeridos**: Top 5 con score de match
- **AÃ±os de experiencia**: Calculados o estimados
- **Tech stack categorizado**: Lenguajes, frameworks, tools
- **Soft skills**: ExtraÃ­das de tu bio
- **Queries optimizadas**: BÃºsquedas recomendadas
- **Fortaleza del perfil**: Score 0-100

**Paso 3: Configurar Filtros** (Tab "ğŸ”§ Filtros")

- **Palabras tÃ³xicas**: Por defecto incluye "rockstar", "ninja", etc.
- **Salario mÃ­nimo**: Define tu expectativa
- **Keywords obligatorias**: TecnologÃ­as que DEBEN estar
- **Preferencias de ubicaciÃ³n**: Remote, hÃ­brido, presencial

**Paso 4: Buscar Empleos** (Tab "ğŸ” BÃºsqueda")

1. Selecciona plataformas: LinkedIn, InfoJobs, RemoteOK
2. Usa las queries sugeridas o escribe tu propia bÃºsqueda
3. El sistema enriquece la bÃºsqueda con tu perfil completo
4. Haz clic en "Buscar Empleos"
5. Espera mientras los agentes navegan las plataformas

**Paso 5: Revisar Resultados** (Tab "ğŸ“‹ Resultados")

- **Ofertas aprobadas**: Score â‰¥ 60/100
- **Ofertas rechazadas**: Con razÃ³n del rechazo
- **Ordenadas por relevancia**: Mejor match primero
- **Exportar**: JSON, CSV
- **Notificaciones automÃ¡ticas**: Si configuraste Telegram/Notion

### Uso ProgramÃ¡tico

#### 1. Extraer y Analizar Perfil Completo

```python
from src.extractors.cv_parser import extract_stack_from_cv
from src.extractors.github_browser_extractor import extract_github_profile_browser
from src.profile.user_profile import UserProfile
from src.profile.profile_analyzer import analyze_profile_and_suggest
import asyncio

async def construir_perfil():
    # 1. Extraer desde CV
    with open('mi_cv.pdf', 'rb') as f:
        cv_data = extract_stack_from_cv(f.read(), 'pdf')

    # 2. Extraer desde GitHub
    github_data = await extract_github_profile_browser('https://github.com/username')

    # 3. Crear perfil unificado
    profile = UserProfile()
    profile.merge_from_cv(cv_data)
    profile.merge_from_github(github_data)

    # 4. Analizar y obtener sugerencias
    analysis = analyze_profile_and_suggest(profile)

    print(f"Nivel: {analysis['level']}")
    print(f"Roles sugeridos: {analysis['suggested_roles']}")
    print(f"Fortaleza del perfil: {analysis['profile_strength']}/100")

    # 5. Guardar perfil
    profile.save('src/data/user_profile.json')

    return profile, analysis

profile, analysis = asyncio.run(construir_perfil())
```

#### 2. Buscar con Contexto Enriquecido

```python
from src.scrapers.linkedin_agent_v2 import LinkedInScraper
from src.profile.user_profile import UserProfile
import asyncio

async def buscar_con_perfil():
    # Cargar perfil
    profile = UserProfile.load('src/data/user_profile.json')

    # Generar contexto enriquecido
    context = profile.generate_search_context()

    # Buscar en LinkedIn con contexto
    scraper = LinkedInScraper()
    jobs = await scraper.scrape(
        search_query="Senior Backend Developer",
        location="Spain",
        max_results=20,
        remote_only=True,
        enriched_context=context  # â† Mejora la precisiÃ³n
    )

    return jobs

jobs = asyncio.run(buscar_con_perfil())
```

#### 3. Filtrar y Notificar

```python
from src.filters.job_filter import JobFilter
from src.notifiers.telegram_notifier import notify_jobs_telegram
import asyncio

# Filtrar con tu tech stack
results = JobFilter.filter_jobs_batch(
    jobs=jobs,
    tech_stack=["Python", "Django", "Docker", "AWS"],
    toxic_keywords=["rockstar", "ninja"],
    min_salary=50000,
    required_keywords=["Python", "backend"]
)

# Notificar a Telegram
approved = results['passed']
asyncio.run(notify_jobs_telegram(
    bot_token="tu_token",
    chat_id="tu_chat_id",
    jobs=approved[:5]  # Top 5
))

print(f"âœ… Aprobadas: {len(approved)}")
print(f"âŒ Rechazadas: {len(results['rejected'])}")
```

#### 4. Pipeline Completo Automatizado

```python
from src.profile.user_profile import UserProfile
from src.profile.profile_analyzer import analyze_profile_and_suggest
from src.scrapers.linkedin_agent_v2 import LinkedInScraper
from src.scrapers.infojobs_agent import InfoJobsScraper
from src.filters.job_filter import JobFilter
from src.notifiers.telegram_notifier import notify_jobs_telegram
import asyncio

async def pipeline_completo():
    # 1. Cargar perfil
    profile = UserProfile.load('src/data/user_profile.json')

    # 2. Analizar y obtener sugerencias
    analysis = analyze_profile_and_suggest(profile)

    print(f"ğŸ¯ Nivel: {analysis['level']}")
    print(f"ğŸ’¼ Top rol sugerido: {analysis['suggested_roles'][0][0]}")

    # 3. Usar queries optimizadas automÃ¡ticamente
    queries = analysis['search_queries']

    all_jobs = []

    # 4. Buscar en mÃºltiples plataformas
    for query in queries[:2]:  # Top 2 queries
        print(f"ğŸ” Buscando: {query}")

        # LinkedIn
        linkedin_scraper = LinkedInScraper()
        linkedin_jobs = await linkedin_scraper.scrape(
            search_query=query,
            location="Remote",
            max_results=10,
            enriched_context=profile.generate_search_context()
        )
        all_jobs.extend(linkedin_jobs)

        # InfoJobs
        infojobs_scraper = InfoJobsScraper()
        infojobs_jobs = await infojobs_scraper.scrape(
            search_query=query,
            location="EspaÃ±a",
            max_results=10
        )
        all_jobs.extend(infojobs_jobs)

    # 5. Filtrar inteligentemente
    tech_stack = profile.technologies + profile.languages + profile.frameworks

    results = JobFilter.filter_jobs_batch(
        jobs=all_jobs,
        tech_stack=tech_stack[:20],  # Top 20 techs
        toxic_keywords=["rockstar", "ninja", "fast-paced"],
        min_salary=40000
    )

    approved = results['passed']

    # 6. Ordenar por score
    approved_sorted = sorted(approved, key=lambda x: x.get('score', 0), reverse=True)

    # 7. Notificar top ofertas
    if approved_sorted:
        await notify_jobs_telegram(
            bot_token="tu_token",
            chat_id="tu_chat_id",
            jobs=approved_sorted[:10]
        )

    print(f"\nâœ… Pipeline completado:")
    print(f"   ğŸ“Š Total escaneadas: {len(all_jobs)}")
    print(f"   âœ… Aprobadas: {len(approved)}")
    print(f"   âŒ Rechazadas: {len(results['rejected'])}")
    print(f"   ğŸ† Mejor score: {approved_sorted[0]['score'] if approved_sorted else 0}")

    return approved_sorted

# Ejecutar
jobs = asyncio.run(pipeline_completo())
```

## ğŸ“ Arquitectura del Proyecto

```
devjobscout/
â”œâ”€â”€ app.py                          # ğŸ¨ AplicaciÃ³n Streamlit principal
â”œâ”€â”€ run.sh                          # ğŸš€ Script de inicio rÃ¡pido
â”œâ”€â”€ pyproject.toml                  # ğŸ“¦ Dependencias y configuraciÃ³n
â”œâ”€â”€ .env                            # ğŸ” Variables de entorno (no versionado)
â”œâ”€â”€ .env.example                    # ğŸ“‹ Template de variables
â”œâ”€â”€ .gitignore                      # ğŸš« Archivos ignorados
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py             # âš™ï¸ ConfiguraciÃ³n centralizada
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/                       # ğŸ” Sistema de autenticaciÃ³n
â”‚   â”‚   â”œâ”€â”€ linkedin_auth.py        # Login manual LinkedIn con Playwright
â”‚   â”‚   â”œâ”€â”€ google_auth.py          # Login Google Drive (futuro)
â”‚   â”‚   â””â”€â”€ session_manager.py      # GestiÃ³n de sesiones persistentes
â”‚   â”‚
â”‚   â”œâ”€â”€ extractors/                 # ğŸ“¤ Extractores de informaciÃ³n
â”‚   â”‚   â”œâ”€â”€ cv_parser.py            # Parser de CV (PDF/TXT/DOCX)
â”‚   â”‚   â”œâ”€â”€ github_browser_extractor.py  # Extractor GitHub con browser-use
â”‚   â”‚   â”œâ”€â”€ github_extractor.py     # Extractor GitHub API (legacy)
â”‚   â”‚   â””â”€â”€ stack_extractor.py      # Extractor de stack (LinkedIn/Portfolio)
â”‚   â”‚
â”‚   â”œâ”€â”€ profile/                    # ğŸ‘¤ Sistema de perfil unificado
â”‚   â”‚   â”œâ”€â”€ user_profile.py         # Clase UserProfile + merge logic
â”‚   â”‚   â””â”€â”€ profile_analyzer.py     # AnÃ¡lisis y sugerencia de roles
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/                   # ğŸ•·ï¸ Web scrapers con browser-use
â”‚   â”‚   â”œâ”€â”€ linkedin_agent_v2.py    # LinkedIn con autenticaciÃ³n
â”‚   â”‚   â”œâ”€â”€ infojobs_agent.py       # InfoJobs
â”‚   â”‚   â””â”€â”€ remoteok_agent.py       # RemoteOK
â”‚   â”‚
â”‚   â”œâ”€â”€ filters/                    # ğŸ¯ Sistema de filtrado
â”‚   â”‚   â””â”€â”€ job_filter.py           # Filtros + scoring + toxic detection
â”‚   â”‚
â”‚   â”œâ”€â”€ notifiers/                  # ğŸ”” Notificadores
â”‚   â”‚   â”œâ”€â”€ telegram_notifier.py    # EnvÃ­o a Telegram
â”‚   â”‚   â””â”€â”€ notion_notifier.py      # Guardado en Notion
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                         # ğŸ¨ Componentes UI
â”‚   â”‚   â””â”€â”€ auth_ui.py              # UI de autenticaciÃ³n
â”‚   â”‚
â”‚   â””â”€â”€ data/                       # ğŸ’¾ Datos persistentes
â”‚       â”œâ”€â”€ user_profile.json       # Perfil unificado
â”‚       â”œâ”€â”€ github_profile.json     # Datos de GitHub
â”‚       â”œâ”€â”€ linkedin_jobs.json      # Ofertas de LinkedIn
â”‚       â”œâ”€â”€ infojobs_jobs.json      # Ofertas de InfoJobs
â”‚       â””â”€â”€ remoteok_jobs.json      # Ofertas de RemoteOK
â”‚
â”œâ”€â”€ sessions/                       # ğŸ” Sesiones de autenticaciÃ³n
â”‚   â””â”€â”€ linkedin_session.json       # Cookies de LinkedIn
â”‚
â”œâ”€â”€ logs/                           # ğŸ“ Logs de browser-use
â”‚   â”œâ”€â”€ github_browser_conversation.json/
â”‚   â”œâ”€â”€ linkedin_conversation.json/
â”‚   â”œâ”€â”€ infojobs_conversation.json/
â”‚   â””â”€â”€ remoteok_conversation.json/
â”‚
â””â”€â”€ docs/                           # ğŸ“š DocumentaciÃ³n
    â”œâ”€â”€ AUTH_GUIDE.md               # GuÃ­a de autenticaciÃ³n
    â””â”€â”€ QUICKSTART.md               # GuÃ­a rÃ¡pida
```

## ğŸ§ª Testing y Debugging

### Test de Componentes Individuales

```bash
# Test CV Parser
uv run python src/extractors/cv_parser.py

# Test GitHub Extractor
uv run python src/extractors/github_browser_extractor.py https://github.com/username

# Test Profile Analyzer
uv run python src/profile/profile_analyzer.py

# Test LinkedIn Scraper
uv run python src/scrapers/linkedin_agent_v2.py

# Test InfoJobs Scraper
uv run python src/scrapers/infojobs_agent.py

# Test RemoteOK Scraper
uv run python src/scrapers/remoteok_agent.py

# Test Filtros
uv run python src/filters/job_filter.py
```

### Debugging con Logs

Browser-use guarda conversaciones detalladas en `logs/`. Para ver quÃ© estÃ¡ haciendo el agente:

```bash
# Ver Ãºltimo log de GitHub
cat logs/github_browser_conversation.json/conversation_*.txt | tail -100

# Ver logs de LinkedIn
ls logs/linkedin_conversation.json/
```

### Modo Verbose

Activa logging detallado en `.env`:

```bash
LOG_LEVEL=DEBUG
HEADLESS=false  # Ver el navegador en acciÃ³n
```

## ğŸ¤– CÃ³mo Funciona Browser-Use

DevJobScout usa [browser-use](https://github.com/browser-use/browser-use) v0.9.5, que permite:

1. **Control con IA**: Los agentes "ven" pÃ¡ginas como humanos usando visiÃ³n por computadora
2. **NavegaciÃ³n autÃ³noma**: Deciden quÃ© hacer segÃºn instrucciones en lenguaje natural
3. **Herramientas custom**: Defines funciones que el agente puede llamar
4. **Persistencia**: Sesiones guardadas para evitar re-logins

**Ejemplo de agente:**

```python
from browser_use import Agent, Browser, ChatBrowserUse, Tools

tools = Tools()

@tools.action('Guarda ofertas de trabajo')
def guardar_ofertas(jobs_json: str) -> str:
    jobs = json.loads(jobs_json)
    # Procesar ofertas...
    return f"âœ… Guardadas {len(jobs)} ofertas"

agent = Agent(
    task="""
    Ve a LinkedIn y busca 'Python developer remote'.
    Extrae las primeras 10 ofertas con: tÃ­tulo, empresa, ubicaciÃ³n, descripciÃ³n.
    Llama a guardar_ofertas con los datos en JSON.
    """,
    llm=ChatBrowserUse(),
    browser=Browser(),
    use_vision=True,
    tools=tools
)

await agent.run()
```

## ğŸ“Š Sistema de Scoring Detallado

Las ofertas se evalÃºan 0-100 segÃºn estos criterios:

| Criterio | Puntos | DescripciÃ³n |
|----------|--------|-------------|
| **Match Tech Stack** | 0-40 | NÃºmero de tecnologÃ­as coincidentes |
| **Keywords Requeridas** | 0-20 | Si las keywords obligatorias estÃ¡n presentes |
| **UbicaciÃ³n** | 0-15 | Coincide con preferencias |
| **Salario** | 0-15 | Cumple mÃ­nimo especificado |
| **SeÃ±ales Positivas** | 0-10 | Remote, benefits, flexible, etc. |

**Penalizaciones:**
- **-20**: Contiene palabras tÃ³xicas (rockstar, ninja, fast-paced)
- **-10**: No cumple salario mÃ­nimo
- **-5**: UbicaciÃ³n no deseada

**Umbral de aprobaciÃ³n**: 60/100

**Ejemplo de cÃ¡lculo:**

```
Oferta: "Senior Python Developer - Remote - â‚¬60k"
Tech Stack Match: 8/10 coincidencias â†’ 32 puntos
Keywords: Tiene "Python" (requerida) â†’ 20 puntos
UbicaciÃ³n: Remote (preferida) â†’ 15 puntos
Salario: â‚¬60k > â‚¬40k (mÃ­nimo) â†’ 15 puntos
SeÃ±ales: Remote, senior â†’ 8 puntos
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: 90/100 âœ… APROBADA
```

## âš ï¸ Limitaciones y Consideraciones

### TÃ©cnicas
- **Rate limiting**: Las plataformas pueden limitar requests. Se recomienda delay entre bÃºsquedas
- **Cambios en sitios**: Los sitios web cambian. Browser-use es resiliente pero puede requerir ajustes
- **Costos API**: Browser-use tiene lÃ­mites segÃºn tu plan
- **Dependencia de sesiones**: LinkedIn requiere autenticaciÃ³n manual inicial

### Legales
- **Terms of Service**: Respeta los ToS de cada plataforma
- **Uso responsable**: No abuses de las bÃºsquedas automatizadas
- **Privacidad**: Tus datos se guardan localmente, nunca se comparten

### PrÃ¡cticas Recomendadas
- No ejecutes scraping masivo (>100 ofertas/hora)
- Usa delays razonables entre requests
- Verifica manualmente ofertas antes de aplicar
- MantÃ©n tus sesiones seguras (no compartas `sessions/`)

## ğŸ”§ PersonalizaciÃ³n Avanzada

### Agregar Nueva Plataforma

1. Crea scraper en `src/scrapers/nueva_plataforma.py`:

```python
from browser_use import Agent, Browser, ChatBrowserUse, Tools
import json

class NuevaPlataformaScraper:
    def __init__(self):
        self.tools = Tools()
        self._setup_tools()

    def _setup_tools(self):
        @self.tools.action('Guarda ofertas')
        def guardar_ofertas(jobs_json: str) -> str:
            jobs = json.loads(jobs_json)
            self.scraped_jobs = jobs
            return f"âœ… {len(jobs)} ofertas guardadas"

    async def scrape(self, search_query: str, max_results: int = 10):
        task = f"""
        Ve a nueva-plataforma.com y busca '{search_query}'.
        Extrae {max_results} ofertas con:
        - title, company, location, salary, description, url
        Llama a guardar_ofertas con el JSON.
        """

        agent = Agent(
            task=task,
            llm=ChatBrowserUse(),
            browser=Browser(),
            use_vision=True,
            tools=self.tools
        )

        await agent.run()
        return self.scraped_jobs
```

2. AgrÃ©galo a `app.py`:

```python
from src.scrapers.nueva_plataforma import NuevaPlataformaScraper

# En el tab de bÃºsqueda
if st.checkbox("Nueva Plataforma"):
    scraper = NuevaPlataformaScraper()
    jobs = await scraper.scrape(query, max_results=10)
```

### Modificar Criterios de Scoring

Edita `src/filters/job_filter.py`:

```python
def filter_job(job: Dict, ...) -> Dict:
    score = 0

    # Modificar pesos
    tech_matches = len(set(tech_stack_lower) & desc_lower_set)
    score += min(tech_matches * 5, 40)  # â† Cambiar de 4 a 5

    # Agregar nuevo criterio
    if 'startup' in description.lower():
        score += 5  # Bonus para startups

    # ...
```

### Personalizar AnÃ¡lisis de Perfil

Edita `src/profile/profile_analyzer.py`:

```python
ROLE_PATTERNS = {
    "Tu Nuevo Rol": {
        "required": ["categoria"],
        "technologies": ["Tech1", "Tech2"],
        "min_tech_count": 2,
        "keywords": ["keyword1", "keyword2"]
    }
}
```

## ğŸ› ï¸ Troubleshooting

### Problemas Comunes

#### "ModuleNotFoundError: No module named 'browser_use'"
```bash
uv sync
```

#### "Browser-use API key invalid"
Verifica que tu API key en `.env` sea correcta. ObtÃ©n una nueva en [browser-use.com](https://browser-use.com).

#### "No se extraen tecnologÃ­as del perfil"
- Verifica que la URL sea pÃºblica
- Revisa logs en `logs/github_browser_conversation.json/`
- Intenta con extracciÃ³n manual desde CV

#### "LinkedIn requiere login cada vez"
La sesiÃ³n puede haber expirado:
```bash
uv run python src/auth/linkedin_auth.py
```

#### "Scrapers no encuentran ofertas"
- Verifica conexiÃ³n a internet
- Revisa logs de browser-use
- El sitio puede haber cambiado estructura (ajusta prompts)

#### "Score siempre bajo"
- Verifica que tu tech stack estÃ© completo en el perfil
- Revisa los criterios de scoring en `job_filter.py`
- Puede que la oferta no coincida con tu perfil

### Logs y Debugging

```bash
# Ver Ãºltimos errores
tail -f logs/linkedin_conversation.json/conversation_*.txt

# Limpiar cachÃ©
rm -rf sessions/*.json
rm -rf src/data/*.json

# Reiniciar sesiÃ³n
uv run python src/auth/linkedin_auth.py
```

## ğŸš€ Roadmap

### PrÃ³ximas Features

- [ ] **ProgramaciÃ³n automÃ¡tica**: Cron jobs para bÃºsquedas periÃ³dicas
- [ ] **MÃ¡s plataformas**: Indeed, Glassdoor, AngelList, Stack Overflow Jobs
- [ ] **Base de datos local**: SQLite para tracking histÃ³rico
- [ ] **DeduplicaciÃ³n**: Detectar ofertas duplicadas entre plataformas
- [ ] **Tracking de aplicaciones**: Seguimiento de estado (aplicado, entrevista, rechazado)
- [ ] **Cover letters automÃ¡ticas**: GeneraciÃ³n con IA basada en oferta + perfil
- [ ] **AnÃ¡lisis de mercado**: Tendencias de salarios, tecnologÃ­as demandadas
- [ ] **Email scraping**: IntegraciÃ³n con Gmail para recibir alertas
- [ ] **Chrome extension**: Analizar ofertas mientras navegas
- [ ] **API REST**: Exponer funcionalidad como servicio

### Mejoras Planificadas

- [ ] Cache inteligente de bÃºsquedas
- [ ] Modo offline con datos guardados
- [ ] ExportaciÃ³n a Excel con formato
- [ ] GrÃ¡ficos de anÃ¡lisis de mercado
- [ ] Sistema de recomendaciones ML
- [ ] Multi-idioma (EN, ES, FR)

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas!

### CÃ³mo Contribuir

1. **Fork** el repositorio
2. **Crea una rama** para tu feature:
   ```bash
   git checkout -b feature/mi-nueva-feature
   ```
3. **Haz tus cambios** con commits descriptivos:
   ```bash
   git commit -m "feat: agrega scraper de Indeed"
   ```
4. **Push** a tu fork:
   ```bash
   git push origin feature/mi-nueva-feature
   ```
5. **Abre un Pull Request** con descripciÃ³n detallada

### Ãreas que Necesitan Ayuda

- **Scrapers**: Nuevas plataformas de empleo
- **Filtros**: Nuevos criterios de evaluaciÃ³n
- **UI**: Mejoras en la interfaz
- **Tests**: Cobertura de tests
- **Docs**: Tutoriales y guÃ­as
- **i18n**: Traducciones

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto bajo licencia **MIT**.

Puedes usar, modificar y distribuir este cÃ³digo libremente, siempre que mantengas el aviso de copyright original.

## ğŸ“§ Soporte y Contacto

- **Issues**: [Abre un issue](https://github.com/tu-repo/devjobscout/issues)
- **Discussions**: Para preguntas y conversaciones
- **Email**: Para consultas privadas

## ğŸ™ Agradecimientos

- [browser-use](https://github.com/browser-use/browser-use) - Framework de automatizaciÃ³n con IA
- [Streamlit](https://streamlit.io) - Framework de UI
- [Playwright](https://playwright.dev) - AutomatizaciÃ³n de navegadores
- [uv](https://github.com/astral-sh/uv) - Gestor de paquetes ultrarrÃ¡pido

## ğŸ“š Recursos Adicionales

- [GuÃ­a de AutenticaciÃ³n](AUTH_GUIDE.md)
- [Quick Start Guide](QUICKSTART.md)
- [Browser-use Docs](https://docs.browser-use.com)
- [Streamlit Docs](https://docs.streamlit.io)

---

**Hecho con â¤ï¸ usando IA y automatizaciÃ³n inteligente**

**Â¿Te ha sido Ãºtil DevJobScout? Dale una â­ en GitHub!**
